<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.89.0" /><meta name="theme-color" content="#fff" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>教程 | 机器学习基础 | ⭐ Moon&#39;s blog</title>

    <link rel="stylesheet" href="/css/meme.min.8707f254c27f9cd000b499c809138fd5594d540dedb9cd6dee71a53680f98e27.css"/>

    
    
        <script src="/js/meme.min.8cbe976441b5181abfd3093c9beee209b19cdbb1fa77c48d225a83ba81fa3fb1.js"></script>

    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" /></noscript>

    <meta name="author" content="玥儿" /><meta name="description" content="这个学期跨选了机器学习基础课程，虽然难度大导致期末成绩不理想，但确实学到了很多机器学习的模型。可能有人会说：自学不就行了……" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="⭐ Moon&#39;s blog" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="⭐ Moon&#39;s blog" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
    <link rel="canonical" href="https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2022-08-04T00:00:00+00:00",
        "dateModified": "2022-08-04T13:23:45+08:00",
        "url": "https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/",
        "headline": "教程 | 机器学习基础",
        "description": "这个学期跨选了机器学习基础课程，虽然难度大导致期末成绩不理想，但确实学到了很多机器学习的模型。可能有人会说：自学不就行了……",
        "inLanguage" : "zh-CN",
        "articleSection": "posts",
        "wordCount":  4450 ,
        "image": "https://moonlee6.github.io/icons/apple-touch-icon.png",
        "author": {
            "@type": "Person",
            "description": "Stay hungry, stay foolish!",
            "email": "moonlee6@icloud.com",
            "image": "https://moonlee6.github.io/icons/apple-touch-icon.png",
            "url": "https://github.com/moonlee6/moonlee6.github.io",
            "name": "玥儿"
        },
        "license": "Copyright © Moon 2022. Generated by [Hugo](https://www.gohugo.cn/)",
        "publisher": {
            "@type": "Organization",
            "name": "⭐ Moon's blog",
            "logo": {
                "@type": "ImageObject",
                "url": "https://moonlee6.github.io/icons/apple-touch-icon.png"
            },
            "url": "https://moonlee6.github.io/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://moonlee6.github.io/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@@mooonoooonooo" />
<meta name="twitter:creator" content="@@mooonoooonooo" />

    



<meta property="og:title" content="教程 | 机器学习基础" />
<meta property="og:description" content="这个学期跨选了机器学习基础课程，虽然难度大导致期末成绩不理想，但确实学到了很多机器学习的模型。可能有人会说：自学不就行了……" />
<meta property="og:url" content="https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" />
<meta property="og:site_name" content="⭐ Moon&#39;s blog" />
<meta property="og:locale" content="zh" /><meta property="og:image" content="https://moonlee6.github.io/icons/apple-touch-icon.png" />
    <meta property="og:type" content="article" />
    <meta property="article:published_time" content="2022-08-04T00:00:00&#43;00:00" />
    <meta property="article:modified_time" content="2022-08-04T13:23:45&#43;08:00" />
    
    <meta property="article:section" content="posts" />



    
    

    
</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">⭐ Moon&#39;s blog</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item"><a href="/posts/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon archive"><path d="M32 448c0 17.7 14.3 32 32 32h384c17.7 0 32-14.3 32-32V160H32v288zm160-212c0-6.6 5.4-12 12-12h104c6.6 0 12 5.4 12 12v8c0 6.6-5.4 12-12 12H204c-6.6 0-12-5.4-12-12v-8zM480 32H32C14.3 32 0 46.3 0 64v48c0 8.8 7.2 16 16 16h480c8.8 0 16-7.2 16-16V64c0-17.7-14.3-32-32-32z"/></svg><span class="menu-item-name">文章</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/categories/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon th"><path d="M149.333 56v80c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V56c0-13.255 10.745-24 24-24h101.333c13.255 0 24 10.745 24 24zm181.334 240v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm32-240v80c0 13.255 10.745 24 24 24H488c13.255 0 24-10.745 24-24V56c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24zm-32 80V56c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256 0 24.001-10.745 24.001-24zm-205.334 56H24c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24zM0 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H24c-13.255 0-24 10.745-24 24zm386.667-56H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zm0 160H488c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255 0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zM181.333 376v80c0 13.255 10.745 24 24 24h101.333c13.255 0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H205.333c-13.255 0-24 10.745-24 24z"/></svg><span class="menu-item-name">分类</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/tags/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" class="icon tags"><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg><span class="menu-item-name">标签</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5l48.8-97.5a18 18 0 0128 0l48.8 97.5 103.4 -34.5a18 18 0 0119.8 19.8l-34.5 103.4l97.5 48.8a18 18 0 010 28l-97.5 48.8 34.5 103.4a18 18 0 01-19.8 19.8l-103.4-34.5-48.8 97.5a18 18 0 01-28 0l-48.8-97.5l-103.4 34.5a18 18 0 01-19.8-19.8l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8-34.5-103.4a18 18 0 0119.8-19.8zM256 128a128 128 0 10.01 0M256 160a96 96 0 10.01 0"/></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412a256 256 0 10154-407a11.5 11.5 0 00-5 20a201.5 201.5 0 01-134 374a11.5 11.5 0 00-15 13"/></svg></a>
                        </li>
                    
                
            
        
            
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            
    <input type="checkbox" id="nav-toggle" aria-hidden="true" />
    <label for="nav-toggle" class="nav-toggle"></label>
    <label for="nav-toggle" class="nav-curtain"></label>


        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-align="justify" data-type="posts" data-toc-num="true">

            <h1 class="post-title p-name">教程 | 机器学习基础</h1>

            

            
                
            

            
                

<div class="post-meta">
    
        
        <time datetime="2022-08-04T00:00:00&#43;00:00" class="post-meta-item published dt-published"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;2022.8.4</time>
    
    
        
        <time datetime="2022-08-04T13:23:45&#43;08:00" class="post-meta-item modified dt-updated"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M400 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627 0-12 5.373-12 12v52H48C21.49 64 0 85.49 0 112v352c0 26.51 21.49 48 48 48h352c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 400H54a6 6 0 0 1-6-6V160h352v298a6 6 0 0 1-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;2022.8.4</time>
    
    
    
        
        
        
            
                <span class="post-meta-item category"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>&nbsp;<a href="/categories/%E6%95%99%E7%A8%8B/" class="category-link p-category">教程</a></span>
            
        
    
    
        
        <span class="post-meta-item wordcount"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;4450</span>
    
    
    
        
            
            <span class="post-meta-item busuanzi-page-pv" id="busuanzi_container_page_pv"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" class="icon post-meta-icon"><path d="M288 144a110.94 110.94 0 0 0-31.24 5 55.4 55.4 0 0 1 7.24 27 56 56 0 0 1-56 56 55.4 55.4 0 0 1-27-7.24A111.71 111.71 0 1 0 288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35 0 0 0 0 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35 0 0 0 0-29.19zM288 400c-98.65 0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 400 288 400z"/></svg>&nbsp;<span id="busuanzi_value_page_pv"></span></span>
        
    
    
</div>

            

            <nav class="contents">
  <h2 id="contents" class="contents-title">目录</h2><ol class="toc">
    <li><a id="contents:逻辑回归" href="#逻辑回归">逻辑回归</a>
      <ol>
        <li><a id="contents:models" href="#models">models</a></li>
        <li><a id="contents:实现" href="#实现">实现</a></li>
      </ol>
    </li>
    <li><a id="contents:heading" href="#heading"></a></li>
    <li><a id="contents:决策树" href="#决策树">决策树</a>
      <ol>
        <li><a id="contents:models-1" href="#models-1">models</a></li>
        <li><a id="contents:可视化" href="#可视化">可视化</a></li>
      </ol>
    </li>
    <li><a id="contents:svm" href="#svm">SVM</a></li>
  </ol>
</nav><div class="post-body e-content">
                <p>这个学期跨选了机器学习基础课程，虽然难度大导致期末成绩不理想，但确实学到了很多机器学习的模型。可能有人会说：自学不就行了，就算上了课也是自己在网上学的。但不上课就没有动力呀，更何况还有老师的耳濡目染和学习路径的指导。以下是机器学习的几个基础模型，格式也是值得学习的。</p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:逻辑回归" class="headings">逻辑回归</a></h2>
<p>小批量梯度下降</p>
<p>数据 <a href="https://github.com/moonlee6/machine-learning/tree/main/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/data" target="_blank" rel="noopener">data</a></p>
<h3 id="models"><a href="#models" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:models" class="headings">models</a></h3>
<p>the Logistic Regression classifier</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span><span class="lnt">91
</span><span class="lnt">92
</span><span class="lnt">93
</span><span class="lnt">94
</span><span class="lnt">95
</span><span class="lnt">96
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#LogisticRegression 模型实现</span>
<span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">:</span>
    <span class="s1">&#39;&#39;&#39;
</span><span class="s1">    Two-class Logistic Regression that learns weights using 二分类逻辑回归
</span><span class="s1">    stochastic gradient descent. 梯度下降算法SGD
</span><span class="s1">    &#39;&#39;&#39;</span>
<span class="c1">#定义类</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">conv_threshold</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        Initializes a LogisticRegression classifer.
</span><span class="s1">
</span><span class="s1">        @attrs:
</span><span class="s1">            n_features: the number of features in the classification problem 特征个数 len(X_train) X_train.shape[1]
</span><span class="s1">            weights: The weights of the Logistic Regression model 特征的权重
</span><span class="s1">            alpha: The learning rate used in stochastic gradient descent 学习率
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_features</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># An extra weight added for the bias   X_train_b</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.03</span>  <span class="c1"># DO NOT TUNE THIS PARAMETER</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_threshold</span> <span class="o">=</span> <span class="n">conv_threshold</span>

<span class="c1">#梯度下降算法训练模型参数 num_epochs = model.train(X_train_b, Y_train)</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        Trains the model using stochastic gradient descent
</span><span class="s1">
</span><span class="s1">        @params:
</span><span class="s1">            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias
</span><span class="s1">            Y: a 1D Numpy array containing the corresponding labels for each example
</span><span class="s1">        @return:
</span><span class="s1">            num_epochs: integer representing the number of epochs taken to reach convergence
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="n">times</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1">#更新次数</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">times</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">Rand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span> <span class="c1">#随机选择每个批量</span>
            <span class="n">X_new</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">Rand</span><span class="p">]</span>
            <span class="n">Y_new</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">Rand</span><span class="p">]</span>
            <span class="n">loss_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> <span class="c1">#计算损失</span>
            <span class="n">weights_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
            <span class="c1">#计算梯度</span>
            <span class="n">gradients</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">@</span> <span class="n">X_new</span><span class="o">.</span><span class="n">T</span><span class="p">))</span> <span class="o">-</span> <span class="n">Y_new</span><span class="p">)</span> <span class="o">@</span> <span class="n">X_new</span> <span class="c1"># @矩阵乘法，np.dot</span>
            <span class="c1">#更新w</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights_old</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">gradients</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> <span class="o">-</span> <span class="n">loss_old</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_threshold</span> <span class="ow">or</span> <span class="n">times</span> <span class="o">&gt;</span> <span class="mf">1e4</span><span class="p">:</span> <span class="c1">#迭代太多次了</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Rand&#39;</span><span class="p">,</span><span class="n">Rand</span><span class="p">)</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">times</span>

<span class="c1">#损失函数</span>
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        Returns the total log loss on some dataset (X, Y), divided by the number of examples.
</span><span class="s1">        @params:
</span><span class="s1">            X: 2D Numpy array where each row contains an example, padded by 1 column for the bias
</span><span class="s1">            Y: 1D Numpy array containing the corresponding labels for each example
</span><span class="s1">        @return:
</span><span class="s1">            A float number which is the average loss of the model on the dataset
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="n">H</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">H</span><span class="p">))</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">H</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        Compute predictions based on the learned weigths and examples X
</span><span class="s1">
</span><span class="s1">        @params:
</span><span class="s1">            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias
</span><span class="s1">        @return:
</span><span class="s1">            A 1D Numpy array with one element for each row in X containing the predicted class.
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="n">H</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)))</span>
        <span class="n">H</span><span class="p">[</span><span class="n">H</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">H</span><span class="p">[</span><span class="n">H</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">H</span>

    <span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        Outputs the accuracy of the trained model on a given testing dataset X and labels Y.
</span><span class="s1">
</span><span class="s1">        @params:
</span><span class="s1">            X: a 2D Numpy array where each row contains an example, padded by 1 column for the bias
</span><span class="s1">            Y: a 1D Numpy array containing the corresponding labels for each example
</span><span class="s1">        @return:
</span><span class="s1">            a float number indicating accuracy (between 0 and 1)
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="n">Y_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y_new</span> <span class="o">==</span> <span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">acc</span>
</code></pre></td></tr></table></div>
</div>
</div><h3 id="实现"><a href="#实现" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:实现" class="headings">实现</a></h3>
<p>models 文件路径</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;os.getcwd()&#39;</span><span class="p">,</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span> 
<span class="n">root_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span>  <span class="c1"># 获取当前文件保存位置的绝对路径</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">root_dir</span><span class="p">)</span> <span class="c1">#设置根目录</span>
<span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">models</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">ROOT_DIR_PREFIX</span> <span class="o">=</span> <span class="s1">&#39;.</span><span class="se">\\</span><span class="s1">data</span><span class="se">\\</span><span class="s1">&#39;</span> <span class="c1">#我也不知道为啥子我的根目录需要再设置</span>

<span class="n">DATA_FILE_NAME</span> <span class="o">=</span> <span class="s1">&#39;normalized_data_binary.csv&#39;</span>


<span class="n">CENSUS_FILE_PATH</span> <span class="o">=</span> <span class="n">ROOT_DIR_PREFIX</span> <span class="o">+</span> <span class="n">DATA_FILE_NAME</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CENSUS_FILE_PATH&#39;</span><span class="p">,</span><span class="n">CENSUS_FILE_PATH</span><span class="p">)</span>
</code></pre></td></tr></table></div>
</div>
</div><p>参数设置</p>
<p>the batch size and convergence threshold</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#一次次试，调整的参数</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1">#tune this parameter</span>
<span class="n">CONV_THRESHOLD</span> <span class="o">=</span> <span class="mf">1e-7</span> <span class="c1">#tune this parameter</span>

<span class="c1">#划分数据集</span>
<span class="k">def</span> <span class="nf">import_census</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        Helper function to import the census dataset
</span><span class="s1">
</span><span class="s1">        @param:
</span><span class="s1">            train_path: path to census train data + labels
</span><span class="s1">            test_path: path to census test data + labels
</span><span class="s1">        @return:
</span><span class="s1">            X_train: training data inputs
</span><span class="s1">            Y_train: training data labels
</span><span class="s1">            X_test: testing data inputs
</span><span class="s1">            Y_test: testing data labels
</span><span class="s1">    &#39;&#39;&#39;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">skip_header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#除了最后一列的所有为属性</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="c1">#最后一列为Lable</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#调包划分训练集和测试集，默认0.25，随机划分</span>
    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span>
</code></pre></td></tr></table></div>
</div>
</div><p>预测</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#模型预测</span>
<span class="k">def</span> <span class="nf">test_logreg</span><span class="p">():</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">import_census</span><span class="p">(</span><span class="n">CENSUS_FILE_PATH</span><span class="p">)</span>
    <span class="n">num_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#矩阵的列数，0为行数</span>

    <span class="c1"># Add a bias</span>
    <span class="n">X_train_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X_test_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1">### Logistic Regression ###调用models 文件</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">CONV_THRESHOLD</span><span class="p">)</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X_train_b</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span> <span class="c1">#模型中权重w的更新次数</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">X_test_b</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Test Accuracy: </span><span class="si">{:.1f}</span><span class="s2">%&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Number of Epochs: &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">acc</span>

<span class="c1">#运行主程序   </span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>

    <span class="c1"># Set random seeds. DO NOT CHANGE THIS IN YOUR FINAL SUBMISSION.</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#设置随机数种子，数据划分也确定</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#np生成X、Y确定</span>

    <span class="n">acc_result</span> <span class="o">=</span> <span class="n">test_logreg</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">acc_result</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></td></tr></table></div>
</div>
</div><h2 id="heading"><a href="#heading" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:heading" class="headings"></a></h2>
<h2 id="决策树"><a href="#决策树" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:决策树" class="headings">决策树</a></h2>
<p>信息增益作为决策指标</p>
<h3 id="models-1"><a href="#models-1" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:models-1" class="headings">models</a></h3>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="s2">&#34;&#34;&#34;
</span><span class="s2">Created on Sun Apr 10 10:15:04 2022
</span><span class="s2">
</span><span class="s2">@author: 
</span><span class="s2">&#34;&#34;&#34;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">TreePlot</span>

<span class="k">class</span> <span class="nc">Node</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_name</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1">#结点为决策结点时，记录所用的决策属性</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subtree</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1">#用字典存储结点下的子树</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_leaf</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1">#表明是否为叶子结点</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaf_class</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1">#结点类标记</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaf_num</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1">#结点下所有叶子结点个数</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1">#结点的高度，即以当前结点为根结点的树的深度</span>


<span class="k">class</span> <span class="nc">DecisionTree</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="s1">&#39;&#39;&#39;
</span><span class="s1">    构造决策树类
</span><span class="s1">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1">#信息增益阈值，当子树的信息增益小于此阈值时，停止决策树的生长（预剪枝）</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        决策树训练
</span><span class="s1">        -------
</span><span class="s1">        :param X:  只支持pd.DataFrame类型数据
</span><span class="s1">        :param y:  只支持pd.Series类型数据
</span><span class="s1">        :return:
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tree_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_ID3tree</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">treescan</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tree_</span><span class="p">)</span>
        
        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">generate_ID3tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        ID3算法生成决策树（参见课上伪代码）：采用信息增益作为特征选择指标，只考虑离散属性，不考虑缺失值
</span><span class="s1">        -------
</span><span class="s1">        :param X:  只支持pd.DataFrame类型数据
</span><span class="s1">        :param y:  只支持pd.Series类型数据
</span><span class="s1">        :return:   返回所生成决策树的根结点
</span><span class="s1">        &#39;&#39;&#39;</span>       
        <span class="n">my_tree</span> <span class="o">=</span> <span class="n">Node</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># 属于同一类别</span>
            <span class="n">my_tree</span><span class="o">.</span><span class="n">is_leaf</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">my_tree</span><span class="o">.</span><span class="n">leaf_class</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">my_tree</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>  <span class="c1"># 特征用完了，数据为空，返回样本数最多的类</span>
            <span class="n">my_tree</span><span class="o">.</span><span class="n">is_leaf</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">my_tree</span><span class="o">.</span><span class="n">leaf_class</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">my_tree</span>

        <span class="n">best_feature_name</span><span class="p">,</span> <span class="n">best_infogain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">choose_best_feature_infogain</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">best_infogain</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>   <span class="c1"># 最佳信息增益小于阈值，返回样本数最多的类</span>
            <span class="n">my_tree</span><span class="o">.</span><span class="n">is_leaf</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">my_tree</span><span class="o">.</span><span class="n">leaf_class</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">my_tree</span>

        <span class="n">my_tree</span><span class="o">.</span><span class="n">feature_name</span> <span class="o">=</span> <span class="n">best_feature_name</span>

        <span class="n">feature_values</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">best_feature_name</span><span class="p">]</span> <span class="c1">#取出</span>

        <span class="n">unique_vals</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">feature_values</span><span class="p">)</span>
        <span class="n">sub_X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">best_feature_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">unique_vals</span><span class="p">:</span>
            <span class="n">my_tree</span><span class="o">.</span><span class="n">subtree</span><span class="p">[</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_ID3tree</span><span class="p">(</span><span class="n">sub_X</span><span class="p">[</span><span class="n">feature_values</span> <span class="o">==</span> <span class="n">value</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">feature_values</span> <span class="o">==</span> <span class="n">value</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">my_tree</span>


    <span class="k">def</span> <span class="nf">choose_best_feature_infogain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        采用信息增益作为指标选择最佳划分属性
</span><span class="s1">        -------
</span><span class="s1">        :X: 当前所有特征的数据 pd.DaraFrame格式
</span><span class="s1">        :y: 标签值
</span><span class="s1">        :return:  以信息增益来选择的最佳划分属性，第一个返回值为最佳属性名称，第二个返回值为最佳信息增益
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span>
        <span class="n">best_feature_name</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">best_info_gain</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
        <span class="n">entD</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">entroy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
            <span class="n">info_gain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_gain</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">feature_name</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">entD</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">info_gain</span> <span class="o">&gt;</span> <span class="n">best_info_gain</span><span class="p">:</span>
                <span class="n">best_feature_name</span> <span class="o">=</span> <span class="n">feature_name</span>
                <span class="n">best_info_gain</span> <span class="o">=</span> <span class="n">info_gain</span>

        <span class="k">return</span> <span class="n">best_feature_name</span><span class="p">,</span> <span class="n">best_info_gain</span>


    <span class="k">def</span> <span class="nf">info_gain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">entD</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        计算信息增益
</span><span class="s1">        ------
</span><span class="s1">        :feature: 当前特征下所有样本值
</span><span class="s1">        :y:       对应标签值
</span><span class="s1">        :return:  当前特征的信息增益
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">unique_value</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>
        
        <span class="n">feature_ent</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">unique_value</span><span class="p">:</span>
            <span class="n">Dv</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">feature</span> <span class="o">==</span> <span class="n">value</span><span class="p">]</span>  <span class="c1"># 当前特征中取值为 value 的样本子集</span>
            <span class="n">feature_ent</span> <span class="o">+=</span> <span class="n">Dv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">m</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">entroy</span><span class="p">(</span><span class="n">Dv</span><span class="p">)</span>

        <span class="n">gain</span> <span class="o">=</span> <span class="n">entD</span> <span class="o">-</span> <span class="n">feature_ent</span>  <span class="c1"># 对应西瓜书4.2式，计算信息增益</span>
        <span class="k">return</span> <span class="n">gain</span>

    
    <span class="k">def</span> <span class="nf">entroy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        计算信息熵
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># 计算各类样本所占比率</span>
        <span class="n">ent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ent</span>
 
    
    <span class="k">def</span> <span class="nf">treescan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">treenode</span><span class="p">):</span>
        <span class="s1">&#39;&#39;&#39;
</span><span class="s1">        扫描决策树，更新树结点的高度、对应叶子结点个数
</span><span class="s1">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">treenode</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">:</span>
            <span class="n">treenode</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">treenode</span><span class="o">.</span><span class="n">leaf_num</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">return</span>
        <span class="n">high</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">leaf_num</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">treenode</span><span class="o">.</span><span class="n">subtree</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">treescan</span><span class="p">(</span><span class="n">treenode</span><span class="o">.</span><span class="n">subtree</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
            <span class="n">leaf_num</span> <span class="o">+=</span> <span class="n">treenode</span><span class="o">.</span><span class="n">subtree</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">leaf_num</span>
            <span class="n">high</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">high</span><span class="p">,</span><span class="mi">1</span><span class="o">+</span><span class="n">treenode</span><span class="o">.</span><span class="n">subtree</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
        <span class="n">treenode</span><span class="o">.</span><span class="n">high</span> <span class="o">=</span> <span class="n">high</span>
        <span class="n">treenode</span><span class="o">.</span><span class="n">leaf_num</span> <span class="o">=</span> <span class="n">leaf_num</span>
        <span class="k">return</span>
            

<span class="k">def</span> <span class="nf">CreateDataSet_Watermelon2</span><span class="p">():</span>
    <span class="s1">&#39;&#39;&#39;
</span><span class="s1">    西瓜书表4.1数据集
</span><span class="s1">    &#39;&#39;&#39;</span>
    <span class="n">dataSet_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="c1"># 1</span>
        <span class="p">[</span><span class="s1">&#39;青绿&#39;</span><span class="p">,</span> <span class="s1">&#39;蜷缩&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;凹陷&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;好瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 2</span>
        <span class="p">[</span><span class="s1">&#39;乌黑&#39;</span><span class="p">,</span> <span class="s1">&#39;蜷缩&#39;</span><span class="p">,</span> <span class="s1">&#39;沉闷&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;凹陷&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;好瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 3</span>
        <span class="p">[</span><span class="s1">&#39;乌黑&#39;</span><span class="p">,</span> <span class="s1">&#39;蜷缩&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;凹陷&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;好瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 4</span>
        <span class="p">[</span><span class="s1">&#39;青绿&#39;</span><span class="p">,</span> <span class="s1">&#39;蜷缩&#39;</span><span class="p">,</span> <span class="s1">&#39;沉闷&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;凹陷&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;好瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 5</span>
        <span class="p">[</span><span class="s1">&#39;浅白&#39;</span><span class="p">,</span> <span class="s1">&#39;蜷缩&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;凹陷&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;好瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 6</span>
        <span class="p">[</span><span class="s1">&#39;青绿&#39;</span><span class="p">,</span> <span class="s1">&#39;稍蜷&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;稍凹&#39;</span><span class="p">,</span> <span class="s1">&#39;软粘&#39;</span><span class="p">,</span> <span class="s1">&#39;好瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 7</span>
        <span class="p">[</span><span class="s1">&#39;乌黑&#39;</span><span class="p">,</span> <span class="s1">&#39;稍蜷&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;稍糊&#39;</span><span class="p">,</span> <span class="s1">&#39;稍凹&#39;</span><span class="p">,</span> <span class="s1">&#39;软粘&#39;</span><span class="p">,</span> <span class="s1">&#39;好瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 8</span>
        <span class="p">[</span><span class="s1">&#39;乌黑&#39;</span><span class="p">,</span> <span class="s1">&#39;稍蜷&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;稍凹&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;好瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 9</span>
        <span class="p">[</span><span class="s1">&#39;乌黑&#39;</span><span class="p">,</span> <span class="s1">&#39;稍蜷&#39;</span><span class="p">,</span> <span class="s1">&#39;沉闷&#39;</span><span class="p">,</span> <span class="s1">&#39;稍糊&#39;</span><span class="p">,</span> <span class="s1">&#39;稍凹&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 10</span>
        <span class="p">[</span><span class="s1">&#39;青绿&#39;</span><span class="p">,</span> <span class="s1">&#39;硬挺&#39;</span><span class="p">,</span> <span class="s1">&#39;清脆&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;平坦&#39;</span><span class="p">,</span> <span class="s1">&#39;软粘&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 11</span>
        <span class="p">[</span><span class="s1">&#39;浅白&#39;</span><span class="p">,</span> <span class="s1">&#39;硬挺&#39;</span><span class="p">,</span> <span class="s1">&#39;清脆&#39;</span><span class="p">,</span> <span class="s1">&#39;模糊&#39;</span><span class="p">,</span> <span class="s1">&#39;平坦&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 12</span>
        <span class="p">[</span><span class="s1">&#39;浅白&#39;</span><span class="p">,</span> <span class="s1">&#39;蜷缩&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;模糊&#39;</span><span class="p">,</span> <span class="s1">&#39;平坦&#39;</span><span class="p">,</span> <span class="s1">&#39;软粘&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 13</span>
        <span class="p">[</span><span class="s1">&#39;青绿&#39;</span><span class="p">,</span> <span class="s1">&#39;稍蜷&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;稍糊&#39;</span><span class="p">,</span> <span class="s1">&#39;凹陷&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 14</span>
        <span class="p">[</span><span class="s1">&#39;浅白&#39;</span><span class="p">,</span> <span class="s1">&#39;稍蜷&#39;</span><span class="p">,</span> <span class="s1">&#39;沉闷&#39;</span><span class="p">,</span> <span class="s1">&#39;稍糊&#39;</span><span class="p">,</span> <span class="s1">&#39;凹陷&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 15</span>
        <span class="p">[</span><span class="s1">&#39;乌黑&#39;</span><span class="p">,</span> <span class="s1">&#39;稍蜷&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;清晰&#39;</span><span class="p">,</span> <span class="s1">&#39;稍凹&#39;</span><span class="p">,</span> <span class="s1">&#39;软粘&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 16</span>
        <span class="p">[</span><span class="s1">&#39;浅白&#39;</span><span class="p">,</span> <span class="s1">&#39;蜷缩&#39;</span><span class="p">,</span> <span class="s1">&#39;浊响&#39;</span><span class="p">,</span> <span class="s1">&#39;模糊&#39;</span><span class="p">,</span> <span class="s1">&#39;平坦&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">],</span>
        <span class="c1"># 17</span>
        <span class="p">[</span><span class="s1">&#39;青绿&#39;</span><span class="p">,</span> <span class="s1">&#39;蜷缩&#39;</span><span class="p">,</span> <span class="s1">&#39;沉闷&#39;</span><span class="p">,</span> <span class="s1">&#39;稍糊&#39;</span><span class="p">,</span> <span class="s1">&#39;稍凹&#39;</span><span class="p">,</span> <span class="s1">&#39;硬滑&#39;</span><span class="p">,</span> <span class="s1">&#39;坏瓜&#39;</span><span class="p">]</span>
    <span class="p">])</span>
 
    <span class="c1"># 特征列表</span>
    <span class="n">features_2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;色泽&#39;</span><span class="p">,</span> <span class="s1">&#39;根蒂&#39;</span><span class="p">,</span> <span class="s1">&#39;敲击&#39;</span><span class="p">,</span> <span class="s1">&#39;纹理&#39;</span><span class="p">,</span> <span class="s1">&#39;脐部&#39;</span><span class="p">,</span> <span class="s1">&#39;触感&#39;</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dataSet_2</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">features_2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">dataSet_2</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">CreateDataSet_Watermelon2</span><span class="p">()</span> <span class="c1">#西瓜书表4.1数据集</span>

    <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTree</span><span class="p">()</span>
    <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1">#训练决策树</span>

    <span class="n">TreePlot</span><span class="o">.</span><span class="n">create_plot</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">tree_</span><span class="p">)</span> <span class="c1">#可视化ID3决策树</span>
</code></pre></td></tr></table></div>
</div>
</div><h3 id="可视化"><a href="#可视化" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:可视化" class="headings">可视化</a></h3>
<p>TreePlot</p>
<div class="highlight"><div class="chroma">
<div class="table-container"><table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="s2">&#34;&#34;&#34;
</span><span class="s2">Created on Sun Apr 10 10:32:50 2022
</span><span class="s2">
</span><span class="s2">@author: liang
</span><span class="s2">&#34;&#34;&#34;</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;STSong&#39;</span>

<span class="n">decision_node</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s1">&#39;round,pad=0.3&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;#FAEBD7&#39;</span><span class="p">)</span>
<span class="n">leaf_node</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s1">&#39;round,pad=0.3&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;#F4A460&#39;</span><span class="p">)</span>
<span class="n">arrow_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s2">&#34;&lt;-&#34;</span><span class="p">)</span>

<span class="n">y_off</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">x_off</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">total_num_leaf</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">total_high</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">plot_node</span><span class="p">(</span><span class="n">node_text</span><span class="p">,</span> <span class="n">center_pt</span><span class="p">,</span> <span class="n">parent_pt</span><span class="p">,</span> <span class="n">node_type</span><span class="p">,</span> <span class="n">ax_</span><span class="p">):</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">node_text</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">[</span><span class="n">parent_pt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">parent_pt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.02</span><span class="p">],</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">&#39;axes fraction&#39;</span><span class="p">,</span>
                 <span class="n">xytext</span><span class="o">=</span><span class="n">center_pt</span><span class="p">,</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;axes fraction&#39;</span><span class="p">,</span>
                 <span class="n">va</span><span class="o">=</span><span class="s2">&#34;center&#34;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&#34;center&#34;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                 <span class="n">bbox</span><span class="o">=</span><span class="n">node_type</span><span class="p">,</span> <span class="n">arrowprops</span><span class="o">=</span><span class="n">arrow_args</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_mid_text</span><span class="p">(</span><span class="n">mid_text</span><span class="p">,</span> <span class="n">center_pt</span><span class="p">,</span> <span class="n">parent_pt</span><span class="p">,</span> <span class="n">ax_</span><span class="p">):</span>
    <span class="n">x_mid</span> <span class="o">=</span> <span class="p">(</span><span class="n">parent_pt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">center_pt</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">center_pt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">y_mid</span> <span class="o">=</span> <span class="p">(</span><span class="n">parent_pt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">center_pt</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">center_pt</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x_mid</span><span class="p">,</span> <span class="n">y_mid</span><span class="p">,</span> <span class="n">mid_text</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">plot_tree</span><span class="p">(</span><span class="n">my_tree</span><span class="p">,</span> <span class="n">parent_pt</span><span class="p">,</span> <span class="n">node_text</span><span class="p">,</span> <span class="n">ax_</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">y_off</span>
    <span class="k">global</span> <span class="n">x_off</span>
    <span class="k">global</span> <span class="n">total_num_leaf</span>
    <span class="k">global</span> <span class="n">total_high</span>

    <span class="n">num_of_leaf</span> <span class="o">=</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">leaf_num</span>
    <span class="n">center_pt</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_off</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">num_of_leaf</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">total_num_leaf</span><span class="p">),</span> <span class="n">y_off</span><span class="p">)</span>

    <span class="n">plot_mid_text</span><span class="p">(</span><span class="n">node_text</span><span class="p">,</span> <span class="n">center_pt</span><span class="p">,</span> <span class="n">parent_pt</span><span class="p">,</span> <span class="n">ax_</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">total_high</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># total_high为零时，表示就直接为一个叶节点。因为西瓜数据集的原因，在预剪枝的时候，有时候会遇到这种情况。</span>
        <span class="n">plot_node</span><span class="p">(</span><span class="n">my_tree</span><span class="o">.</span><span class="n">leaf_class</span><span class="p">,</span> <span class="n">center_pt</span><span class="p">,</span> <span class="n">parent_pt</span><span class="p">,</span> <span class="n">leaf_node</span><span class="p">,</span> <span class="n">ax_</span><span class="p">)</span>
        <span class="k">return</span>
    <span class="n">plot_node</span><span class="p">(</span><span class="n">my_tree</span><span class="o">.</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">center_pt</span><span class="p">,</span> <span class="n">parent_pt</span><span class="p">,</span> <span class="n">decision_node</span><span class="p">,</span> <span class="n">ax_</span><span class="p">)</span>

    <span class="n">y_off</span> <span class="o">-=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">total_high</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">subtree</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">my_tree</span><span class="o">.</span><span class="n">subtree</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">is_leaf</span><span class="p">:</span>
            <span class="n">x_off</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">total_num_leaf</span>
            <span class="n">plot_node</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">my_tree</span><span class="o">.</span><span class="n">subtree</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">leaf_class</span><span class="p">),</span> <span class="p">(</span><span class="n">x_off</span><span class="p">,</span> <span class="n">y_off</span><span class="p">),</span> <span class="n">center_pt</span><span class="p">,</span> <span class="n">leaf_node</span><span class="p">,</span> <span class="n">ax_</span><span class="p">)</span>
            <span class="n">plot_mid_text</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="p">(</span><span class="n">x_off</span><span class="p">,</span> <span class="n">y_off</span><span class="p">),</span> <span class="n">center_pt</span><span class="p">,</span> <span class="n">ax_</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plot_tree</span><span class="p">(</span><span class="n">my_tree</span><span class="o">.</span><span class="n">subtree</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">center_pt</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">ax_</span><span class="p">)</span>
    <span class="n">y_off</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">total_high</span>


<span class="k">def</span> <span class="nf">create_plot</span><span class="p">(</span><span class="n">tree_</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">y_off</span>
    <span class="k">global</span> <span class="n">x_off</span>
    <span class="k">global</span> <span class="n">total_num_leaf</span>
    <span class="k">global</span> <span class="n">total_high</span>

    <span class="n">total_num_leaf</span> <span class="o">=</span> <span class="n">tree_</span><span class="o">.</span><span class="n">leaf_num</span>
    <span class="n">total_high</span> <span class="o">=</span> <span class="n">tree_</span><span class="o">.</span><span class="n">high</span>
    <span class="n">y_off</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">x_off</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">/</span> <span class="n">total_num_leaf</span>

    <span class="n">fig_</span><span class="p">,</span> <span class="n">ax_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>  <span class="c1"># 隐藏坐标轴刻度</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>  <span class="c1"># 设置隐藏坐标轴</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">ax_</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;left&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">plot_tree</span><span class="p">(</span><span class="n">tree_</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">ax_</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></td></tr></table></div>
</div>
</div><h2 id="svm"><a href="#svm" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:svm" class="headings">SVM</a></h2>
<p><a href="https://github.com/moonlee6/machine-learning/blob/main/hw4_SVM.ipynb" target="_blank" rel="noopener">Support vector classifier</a></p>

            </div>

            


        </article>

        

        
    <div class="updated-badge-container">
        <span title="Updated @ 2022-08-04 13:23:45 CST" style="cursor:help">

<svg xmlns="http://www.w3.org/2000/svg" width="130" height="20" class="updated-badge"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#a)"><path class="updated-badge-left" d="M0 0h55v20H0z"/><path class="updated-badge-right" d="M55 0h75v20H55z"/><path fill="url(#b)" d="M0 0h130v20H0z"/></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2022-08-04</text><text x="915" y="140" textLength="650" transform="scale(.1)">2022-08-04</text></g></svg>
        </span></div>



        


        <div class="post-share">

        

        <div class="share-items">

            
                <div class="share-item twitter">
                    
                    <a href="https://twitter.com/share?url=https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/&amp;text=%e6%95%99%e7%a8%8b%20%7c%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80&amp;hashtags=Python,%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0,&amp;via=@mooonoooonooo" title="分享到「Twitter」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </div>
            

            
                <div class="share-item facebook">
                    
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/&amp;hashtag=%23Python" title="分享到「Facebook」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon facebook-icon"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></a>
                </div>
            

            
                <div class="share-item linkedin">
                    
                    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/&amp;title=%e6%95%99%e7%a8%8b%20%7c%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80&amp;summary=%e8%bf%99%e4%b8%aa%e5%ad%a6%e6%9c%9f%e8%b7%a8%e9%80%89%e4%ba%86%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80%e8%af%be%e7%a8%8b%ef%bc%8c%e8%99%bd%e7%84%b6%e9%9a%be%e5%ba%a6%e5%a4%a7%e5%af%bc%e8%87%b4%e6%9c%9f%e6%9c%ab%e6%88%90%e7%bb%a9%e4%b8%8d%e7%90%86%e6%83%b3%ef%bc%8c%e4%bd%86%e7%a1%ae%e5%ae%9e%e5%ad%a6%e5%88%b0%e4%ba%86%e5%be%88%e5%a4%9a%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%a8%a1%e5%9e%8b%e3%80%82%e5%8f%af%e8%83%bd%e6%9c%89%e4%ba%ba%e4%bc%9a%e8%af%b4%ef%bc%9a%e8%87%aa%e5%ad%a6%e4%b8%8d%e5%b0%b1%e8%a1%8c%e4%ba%86%e2%80%a6%e2%80%a6&amp;source=%e2%ad%90%20Moon%27s%20blog" title="分享到「LinkedIn」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon linkedin-icon"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
                </div>
            

            
                <div class="share-item telegram">
                    
                    <a href="https://t.me/share/url?url=https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/&amp;text=%e6%95%99%e7%a8%8b%20%7c%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80" title="分享到「Telegram」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon telegram-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9l-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a>
                </div>
            

            
                <div class="share-item weibo">
                    
                    <a href="https://service.weibo.com/share/share.php?&amp;url=https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/&amp;title=%e6%95%99%e7%a8%8b%20%7c%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80&amp;pic=https://moonlee6.github.io/icons/apple-touch-icon.png&amp;searchPic=false" title="分享到「新浪微博」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon weibo-icon"><path d="M407 177.6c7.6-24-13.4-46.8-37.4-41.7-22 4.8-28.8-28.1-7.1-32.8 50.1-10.9 92.3 37.1 76.5 84.8-6.8 21.2-38.8 10.8-32-10.3zM214.8 446.7C108.5 446.7 0 395.3 0 310.4c0-44.3 28-95.4 76.3-143.7C176 67 279.5 65.8 249.9 161c-4 13.1 12.3 5.7 12.3 6 79.5-33.6 140.5-16.8 114 51.4-3.7 9.4 1.1 10.9 8.3 13.1 135.7 42.3 34.8 215.2-169.7 215.2zm143.7-146.3c-5.4-55.7-78.5-94-163.4-85.7-84.8 8.6-148.8 60.3-143.4 116s78.5 94 163.4 85.7c84.8-8.6 148.8-60.3 143.4-116zM347.9 35.1c-25.9 5.6-16.8 43.7 8.3 38.3 72.3-15.2 134.8 52.8 111.7 124-7.4 24.2 29.1 37 37.4 12 31.9-99.8-55.1-195.9-157.4-174.3zm-78.5 311c-17.1 38.8-66.8 60-109.1 46.3-40.8-13.1-58-53.4-40.3-89.7 17.7-35.4 63.1-55.4 103.4-45.1 42 10.8 63.1 50.2 46 88.5zm-86.3-30c-12.9-5.4-30 .3-38 12.9-8.3 12.9-4.3 28 8.6 34 13.1 6 30.8.3 39.1-12.9 8-13.1 3.7-28.3-9.7-34zm32.6-13.4c-5.1-1.7-11.4.6-14.3 5.4-2.9 5.1-1.4 10.6 3.7 12.9 5.1 2 11.7-.3 14.6-5.4 2.8-5.2 1.1-10.9-4-12.9z"/></svg></a>
                </div>
            

            
                <div class="share-item douban">
                    
                    <a href="https://www.douban.com/share/service?href=https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/&amp;name=%e6%95%99%e7%a8%8b%20%7c%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80&amp;text=%e8%bf%99%e4%b8%aa%e5%ad%a6%e6%9c%9f%e8%b7%a8%e9%80%89%e4%ba%86%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80%e8%af%be%e7%a8%8b%ef%bc%8c%e8%99%bd%e7%84%b6%e9%9a%be%e5%ba%a6%e5%a4%a7%e5%af%bc%e8%87%b4%e6%9c%9f%e6%9c%ab%e6%88%90%e7%bb%a9%e4%b8%8d%e7%90%86%e6%83%b3%ef%bc%8c%e4%bd%86%e7%a1%ae%e5%ae%9e%e5%ad%a6%e5%88%b0%e4%ba%86%e5%be%88%e5%a4%9a%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%a8%a1%e5%9e%8b%e3%80%82%e5%8f%af%e8%83%bd%e6%9c%89%e4%ba%ba%e4%bc%9a%e8%af%b4%ef%bc%9a%e8%87%aa%e5%ad%a6%e4%b8%8d%e5%b0%b1%e8%a1%8c%e4%ba%86%e2%80%a6%e2%80%a6" title="分享到「豆瓣」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon douban-icon"><path d="M.643.92v2.412h22.714V.92H.643zm1.974 4.926v9.42h18.764v-9.42H2.617zm2.72 2.408H18.69v4.605H5.338V8.254zm1.657 7.412l-2.512.938c1.037 1.461 1.87 2.825 2.512 4.091H0v2.385h24v-2.385h-6.678c.818-1.176 1.589-2.543 2.303-4.091l-2.73-.938a29.952 29.952 0 01-2.479 5.03h-4.75c-.786-1.962-1.677-3.641-2.672-5.03Z"/></svg></a>
                </div>
            

            
                <div class="share-item qq">
                    
                    <a href="https://connect.qq.com/widget/shareqq/index.html?url=https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/&amp;title=%e6%95%99%e7%a8%8b%20%7c%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80&amp;summary=%e8%bf%99%e4%b8%aa%e5%ad%a6%e6%9c%9f%e8%b7%a8%e9%80%89%e4%ba%86%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80%e8%af%be%e7%a8%8b%ef%bc%8c%e8%99%bd%e7%84%b6%e9%9a%be%e5%ba%a6%e5%a4%a7%e5%af%bc%e8%87%b4%e6%9c%9f%e6%9c%ab%e6%88%90%e7%bb%a9%e4%b8%8d%e7%90%86%e6%83%b3%ef%bc%8c%e4%bd%86%e7%a1%ae%e5%ae%9e%e5%ad%a6%e5%88%b0%e4%ba%86%e5%be%88%e5%a4%9a%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%a8%a1%e5%9e%8b%e3%80%82%e5%8f%af%e8%83%bd%e6%9c%89%e4%ba%ba%e4%bc%9a%e8%af%b4%ef%bc%9a%e8%87%aa%e5%ad%a6%e4%b8%8d%e5%b0%b1%e8%a1%8c%e4%ba%86%e2%80%a6%e2%80%a6&amp;pics=https://moonlee6.github.io/icons/apple-touch-icon.png&amp;site=%e2%ad%90%20Moon%27s%20blog" title="分享到「QQ」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qq-icon"><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z"/></svg></a>
                </div>
            

            
                <div class="share-item qzone">
                    
                    <a href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://moonlee6.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/&amp;title=%e6%95%99%e7%a8%8b%20%7c%20%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80&amp;summary=%e8%bf%99%e4%b8%aa%e5%ad%a6%e6%9c%9f%e8%b7%a8%e9%80%89%e4%ba%86%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80%e8%af%be%e7%a8%8b%ef%bc%8c%e8%99%bd%e7%84%b6%e9%9a%be%e5%ba%a6%e5%a4%a7%e5%af%bc%e8%87%b4%e6%9c%9f%e6%9c%ab%e6%88%90%e7%bb%a9%e4%b8%8d%e7%90%86%e6%83%b3%ef%bc%8c%e4%bd%86%e7%a1%ae%e5%ae%9e%e5%ad%a6%e5%88%b0%e4%ba%86%e5%be%88%e5%a4%9a%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%9a%84%e6%a8%a1%e5%9e%8b%e3%80%82%e5%8f%af%e8%83%bd%e6%9c%89%e4%ba%ba%e4%bc%9a%e8%af%b4%ef%bc%9a%e8%87%aa%e5%ad%a6%e4%b8%8d%e5%b0%b1%e8%a1%8c%e4%ba%86%e2%80%a6%e2%80%a6&amp;pics=https://moonlee6.github.io/icons/apple-touch-icon.png&amp;site=%e2%ad%90%20Moon%27s%20blog" title="分享到「QQ 空间」" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon qzone-icon"><path d="M23.985 9.202c-.032-.099-.127-.223-.334-.258-.207-.036-7.351-1.406-7.351-1.406s-.105-.022-.198-.07c-.092-.047-.127-.167-.127-.167S12.447.956 12.349.77C12.25.583 12.104.532 12 .532c-.104 0-.251.051-.349.238-.098.186-3.626 6.531-3.626 6.531s-.035.12-.128.167c-.092.047-.197.07-.197.07S.556 8.908.348 8.943c-.208.036-.302.16-.333.258a.477.477 0 0 0 .125.449l5.362 5.49s.072.08.119.172c.016.104.005.21.005.21s-1.189 7.242-1.22 7.45.075.369.159.43c.083.062.233.106.421.013.189-.093 6.812-3.261 6.812-3.261s.098-.044.201-.061c.103-.017.201.061.201.061s6.623 3.168 6.812 3.261c.188.094.338.049.421-.013a.463.463 0 0 0 .159-.43c-.021-.14-.93-5.677-.93-5.677.876-.54 1.425-1.039 1.849-1.747-2.594.969-6.006 1.717-9.415 1.866-.915.041-2.41.097-3.473-.015-.678-.071-1.17-.144-1.243-.438-.053-.215.054-.46.545-.831a2640.5 2640.5 0 0 1 2.861-2.155c1.285-.968 3.559-2.47 3.559-2.731 0-.285-2.144-.781-4.037-.781-1.945 0-2.275.132-2.811.168-.488.034-.769.005-.804-.138-.06-.248.183-.389.588-.568.709-.314 1.86-.594 1.984-.626.194-.052 3.082-.805 5.618-.535 1.318.14 3.244.668 3.244 1.276 0 .342-1.721 1.494-3.225 2.597-1.149.843-2.217 1.561-2.217 1.688 0 .342 3.533 1.241 6.689 1.01l.003-.022c.048-.092.119-.172.119-.172l5.362-5.49a.477.477 0 0 0 .127-.449z"/></svg></a>
                </div>
            

            
                <div class="share-item qrcode">
                    <div class="qrcode-container" title="通过「二维码」"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon qrcode-icon"><path d="M0 224h192V32H0v192zM64 96h64v64H64V96zm192-64v192h192V32H256zm128 128h-64V96h64v64zM0 480h192V288H0v192zm64-128h64v64H64v-64zm352-64h32v128h-96v-32h-32v96h-64V288h96v32h64v-32zm0 160h32v32h-32v-32zm-64 0h32v32h-32v-32z"/></svg><div id="qrcode-img"></div>
                    </div>
                    <script src="https://cdn.jsdelivr.net/npm/qrcode-generator@1.4.4/qrcode.min.js"></script>

<script>
    var typeNumber = 0;
    var errorCorrectionLevel = 'L';
    var qr = qrcode(typeNumber, errorCorrectionLevel);
    qr.addData('https:\/\/moonlee6.github.io\/posts\/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80\/');
    qr.make();
    document.getElementById('qrcode-img').innerHTML = qr.createImgTag();
</script>

                </div>
            

        </div>

    </div>




        
    
    
        <div class="related-posts">
            <h2 class="related-title">相关文章：<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon related-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm144 276c0 6.6-5.4 12-12 12h-92v92c0 6.6-5.4 12-12 12h-56c-6.6 0-12-5.4-12-12v-92h-92c-6.6 0-12-5.4-12-12v-56c0-6.6 5.4-12 12-12h92v-92c0-6.6 5.4-12 12-12h56c6.6 0 12 5.4 12 12v92h92c6.6 0 12 5.4 12 12v56z"/></svg></h2>
            <ul class="related-list">
                
                    <li class="related-item">
                        <a href="/posts/%E7%96%BE%E7%97%85%E9%A2%84%E6%B5%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="related-link">实践 | 疾病预测机器学习</a>
                    </li>
                
                    <li class="related-item">
                        <a href="/posts/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2hugo&#43;git/" class="related-link">教程 | 搭建个人博客</a>
                    </li>
                
            </ul>
        </div>
    



        
    
        <div class="post-tags">
            
                
                
                
                
                    
                    <a href="/tags/python/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>Python</a>
                
            
                
                
                
                
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag" class="post-tags-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 0 1 0 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>机器学习</a>
                
            
        </div>
    



        


        


        
    
        
        
    
    
    
    
        <ul class="post-nav">
            
                <li class="post-nav-prev">
                    <a href="/posts/%E7%96%BE%E7%97%85%E9%A2%84%E6%B5%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="prev">&lt; 实践 | 疾病预测机器学习</a>
                </li>
            
            
                <li class="post-nav-next">
                    <a href="/posts/2022_8_3/" rel="next">日记 | Friday Sunny &gt;</a>
                </li>
            
        </ul>
    



        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            
    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="site-info">2022&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg>&nbsp;玥儿</div><div class="site-copyright">Copyright © Moon 2022. Generated by <a href="https://www.gohugo.cn/" target="_blank" rel="noopener">Hugo</a></div><div class="custom-footer">每一片羽翼都闪耀着自由的光辉。</div>
                <div class="busuanzi-site-uv-and-pv">
                    <span id="busuanzi_container_site_uv">本站访客数&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon busuanzi-site-uv"><path d="M224 256c70.7 0 128-57.3 128-128S294.7 0 224 0 96 57.3 96 128s57.3 128 128 128zm89.6 32h-16.7c-22.2 10.2-46.9 16-72.9 16s-50.6-5.8-72.9-16h-16.7C60.2 288 0 348.2 0 422.4V464c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48v-41.6c0-74.2-60.2-134.4-134.4-134.4z"/></svg>&nbsp;<span id="busuanzi_value_site_uv"></span></span>&nbsp;|&nbsp;<span id="busuanzi_container_site_pv">本站访问量&nbsp;<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" class="icon busuanzi-site-pv"><path d="M288 144a110.94 110.94 0 0 0-31.24 5 55.4 55.4 0 0 1 7.24 27 56 56 0 0 1-56 56 55.4 55.4 0 0 1-27-7.24A111.71 111.71 0 1 0 288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35 0 0 0 0 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35 0 0 0 0-29.19zM288 400c-98.65 0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 400 288 400z"/></svg>&nbsp;<span id="busuanzi_value_site_pv"></span></span>
                </div>

            
    
        <ul class="socials"><li class="socials-item">
                    <a href="/rss.xml" target="_blank" rel="external noopener" title="RSS"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M19.199 24C19.199 13.467 10.533 4.8 0 4.8V0c13.165 0 24 10.835 24 24h-4.801zM3.291 17.415c1.814 0 3.293 1.479 3.293 3.295 0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526 0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727 0 15.909 7.184 15.909 15.91z"/></svg></a>
                </li><li class="socials-item">
                    <a href="mailto:moonlee6@icloud.com" target="_blank" rel="external noopener" title="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://github.com/moonlee6" target="_blank" rel="external noopener" title="GitHub"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="icon social-icon"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://twitter.com/mooonoooonooo" target="_blank" rel="external noopener" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon social-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a>
                </li><li class="socials-item">
                    <a href="https://space.bilibili.com/392667860" target="_blank" rel="external noopener" title="B站"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon social-icon"><path d="M433.754 420.445c-11.526 1.393-44.86-52.741-44.86-52.741 0 31.345-16.136 72.247-51.051 101.786 16.842 5.192 54.843 19.167 45.803 34.421-7.316 12.343-125.51 7.881-159.632 4.037-34.122 3.844-152.316 8.306-159.632-4.037-9.045-15.25 28.918-29.214 45.783-34.415-34.92-29.539-51.059-70.445-51.059-101.792 0 0-33.334 54.134-44.859 52.741-5.37-.65-12.424-29.644 9.347-99.704 10.261-33.024 21.995-60.478 40.144-105.779C60.683 98.063 108.982.006 224 0c113.737.006 163.156 96.133 160.264 214.963 18.118 45.223 29.912 72.85 40.144 105.778 21.768 70.06 14.716 99.053 9.346 99.704z"/></svg></a>
                </li></ul>
    



            
        </div>
    </footer>


        </div>
        

        
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css" integrity="sha256-gPJfuwTULrEAAcI3X4bALVU/2qBU+QY/TpoD3GO+Exw=" crossorigin="anonymous">
<script>
    if (typeof renderMathInElement === 'undefined') {
        var getScript = (options) => {
            var script = document.createElement('script');
            script.defer = true;
            script.crossOrigin = 'anonymous';
            Object.keys(options).forEach((key) => {
                script[key] = options[key];
            });
            document.body.appendChild(script);
        };
        getScript({
            src: 'https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js',
            integrity: 'sha256-YTW9cMncW/ZQMhY69KaUxIa2cPTxV87Uh627Gf5ODUw=',
            onload: () => {
                getScript({
                    src: 'https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/mhchem.min.js',
                    integrity: 'sha256-yzSfYeVsWJ1x+2g8CYHsB/Mn7PcSp8122k5BM4T3Vxw=',
                    onload: () => {
                        getScript({
                            src: 'https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js',
                            integrity: 'sha256-fxJzNV6hpc8tgW8tF0zVobKa71eTCRGTgxFXt1ZpJNM=',
                            onload: () => {
                                renderKaTex();
                            }
                        });
                    }
                });
            }
        });
    } else {
        renderKaTex();
    }
    function renderKaTex() {
        renderMathInElement(
            document.body,
            {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "\\[", right: "\\]", display: true},
                    {left: "$", right: "$", display: false},
                    {left: "\\(", right: "\\)", display: false}
                ]
            }
        );
    }
</script>




    <script>
    if (typeof MathJax === 'undefined') {
        window.MathJax = {
            loader: {
                load: ['[tex]/mhchem']
            },
            
            tex: {
                inlineMath: {'[+]': [['$', '$']]},
                tags: 'ams',
                packages: {'[+]': ['mhchem']}
            }
        };
        (function() {
            var script = document.createElement('script');
            script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
            script.defer = true;
            document.head.appendChild(script);
        })();
    } else {
        MathJax.texReset();
        MathJax.typeset();
    }
</script>








    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js"></script>

<script>
    let imgNodes = document.querySelectorAll('div.post-body img');
    imgNodes = Array.from(imgNodes).filter(node => node.parentNode.tagName !== "A");

    mediumZoom(imgNodes, {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>




    
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    




    </body>
</html>
